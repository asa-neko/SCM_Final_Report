{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52f3c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解析\n",
    "# データの取得\n",
    "!wget http://misc.0093.tv/misc/kadai.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb79985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae611427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b813d803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの確認\n",
    "df = pd.read_excel(\"kadai.xlsx\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c366ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本統計量\n",
    "df.describe().T[['count','mean','std','min','50%','max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c069ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相関行列の確認（多重共線性のチェック）\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr_matrix = df.corr()\n",
    "sns.heatmap(corr_matrix, annot=False, fmt=\".2f\", cmap='coolwarm', square=True)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec75712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変数の指定\n",
    "target = 'OV'\n",
    "features = df.drop(columns=[target]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17efbb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理と外れ値の処理\n",
    "# 0. \"process_end_time\"と\"final_mes_time\"を時系列オブジェクトに変換する\n",
    "df[\"process_end_time\"] = pd.to_datetime(df[\"process_end_time\"])\n",
    "df[\"final_mes_time\"] = pd.to_datetime(df[\"final_mes_time\"])\n",
    "\n",
    "# 1. 欠損値の確認\n",
    "df.info()\n",
    "\n",
    "# 2. 外れ値の確認(IQR法)\n",
    "Q1 = df[target].quantile(0.25)\n",
    "Q3 = df[target].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliners = df[(df[target] < lower_bound) | (df[target] > upper_bound)]\n",
    "print(f\"目的変数{target}の外れ値：{len(outliners)}個\")\n",
    "print(outliners[[target]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36bbac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量エンジニアリング\n",
    "# 1. Lag特徴量\n",
    "lags = [1, 2, 3, 5]\n",
    "for lag in lags:\n",
    "  df[f\"{target}_lag{lag}\"] = df[target].shift(lag)\n",
    "\n",
    "# 2. 差分特徴量\n",
    "df[f\"{target}_diff\"] = df[target].diff(1).shift(1)\n",
    "\n",
    "# 3. 移動平均と移動標準偏差\n",
    "windows = [3, 5]\n",
    "for window in windows:\n",
    "  df[f\"{target}_roll_mean{window}\"] = df[target].rolling(window).mean().shift(1)\n",
    "  df[f\"{target}_roll_std{window}\"] = df[target].rolling(window).std().shift(1)\n",
    "\n",
    "# 4. Shiftへの対応\n",
    "df = df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379daa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変数選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b9eda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルのパラメータ(線形回帰、勾配ブースティング回帰、RF、XGB、SVM、LightGBM)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# 線形回帰\n",
    "def objective_linear(trial):\n",
    "    param = {\n",
    "        'alpha': trial.suggest_categorical('alpha', [0.1, 1, 10]),\n",
    "        'max_iter': 100000,\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    model = Lasso(**param)\n",
    "\n",
    "    scores = cross_val_score(model, X_init_origin, y_init_origin, cv=tscv, scoring='neg_root_mean_squared_error')\n",
    "    return -scores.mean()\n",
    "\n",
    "# 勾配ブースティング回帰\n",
    "def objective_gbr(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', [100, 300, 500]),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.01, 0.05, 0.1]),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [3, 5, 7]),\n",
    "        'min_samples_leaf': trial.suggest_categorical('min_samples_leaf', [1, 2, 4]),\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.8, 1.0]),\n",
    "        'loss': trial.suggest_categorical('loss', ['squared_error', 'huber']),\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    model = GradientBoostingRegressor(**param)\n",
    "\n",
    "    scores = cross_val_score(model, X_init_scaled, y_init, cv=tscv, scoring='neg_root_mean_squared_error')\n",
    "    return -scores.mean()\n",
    "\n",
    "# ランダムフォレスト\n",
    "def objective_rf(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', [100, 300, 500]),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [3, 5, 7, 9]),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', 0.5]),\n",
    "        'min_samples_leaf': trial.suggest_categorical('min_samples_leaf', [1, 2, 4, 10]),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "\n",
    "    model = RandomForestRegressor(**param)\n",
    "    scores = cross_val_score(model, X_init_scaled, y_init, cv=tscv, scoring='neg_root_mean_squared_error')\n",
    "    return -scores.mean()\n",
    "\n",
    "# XGBoost\n",
    "def objective_xgb(trial):\n",
    "    param = {\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.05, 0.1, 0.2, 0.3]),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [3, 5, 7]),\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'reg_alpha': trial.suggest_categorical('reg_alpha', [0, 0.1, 1, 10]),\n",
    "        'reg_lambda': trial.suggest_categorical('reg_lambda', [1, 5, 9]),\n",
    "        'n_estimators': 1000,\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBRegressor(**param)\n",
    "    scores = cross_val_score(model, X_init_scaled, y_init, cv=tscv, scoring='neg_root_mean_squared_error')\n",
    "    return -scores.mean()\n",
    "\n",
    "# SVM\n",
    "def objective_svm(trial):\n",
    "    param = {\n",
    "        'C': trial.suggest_categorical('C', [0.1, 1, 10, 100]),\n",
    "        'epsilon': trial.suggest_categorical('epsilon', [0.01, 0.1, 0.5]),\n",
    "        'kernel': 'rbf',\n",
    "        'gamma': trial.suggest_categorical('gamma', ['scale', 0.001, 0.01, 0.1])\n",
    "    }\n",
    "\n",
    "    model = SVR(**param)\n",
    "    scores = cross_val_score(model, X_init_scaled, y_init, cv=tscv, scoring='neg_root_mean_squared_error')\n",
    "    return -scores.mean()\n",
    "\n",
    "# LightGBM\n",
    "def objective_lgb(trial):\n",
    "    param = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.01, 0.05, 0.1]),\n",
    "        'min_child_samples': 20,\n",
    "        'n_estimators': 1000,\n",
    "        'random_state': 42,\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMRegressor(**param)\n",
    "\n",
    "    scores = cross_val_score(model, X_init_scaled, y_init, cv=tscv, scoring='neg_root_mean_squared_error')\n",
    "    return -scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c588f13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適モデルの保存場所\n",
    "from google.colab import drive\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# ドライブをマウント（初回のみ認証が必要）\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 保存用ディレクトリを作成（エラーにならないよう exist_ok=True）\n",
    "save_dir = '/content/drive/MyDrive/Colab_ML_Params'\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89e60d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea07c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータチューニング\n",
    "file_path = save_dir\n",
    "\n",
    "# パラメータチューニング用データ\n",
    "learn_init = df[0:1776]\n",
    "#X_init = learn_init.drop(columns=['process_end_time','final_mes_time',target], axis=1)\n",
    "y_init = learn_init[target]\n",
    "X_init = learn_init[selected_features]\n",
    "\n",
    "learn_init1 = df1[0:1776]\n",
    "#X_init_origin = learn_init1.drop(columns=['process_end_time','final_mes_time',target], axis=1)\n",
    "y_init_origin = learn_init1[target]\n",
    "X_init_origin = learn_init1[selected_features]\n",
    "\n",
    "# 標準化(SVM用)\n",
    "scaler = StandardScaler()\n",
    "X_init_scaled = scaler.fit_transform(X_init)\n",
    "scaler2 = StandardScaler()\n",
    "X_init_origin = scaler2.fit_transform(X_init_origin)\n",
    "\n",
    "# 線形回帰\n",
    "print(\"---------- 線形回帰モデル(Lasso) ----------\")\n",
    "lr_init = optuna.create_study(direction='minimize')\n",
    "lr_init.optimize(objective_linear, n_trials=10)\n",
    "lr_best_params = lr_init.best_params\n",
    "best_lr = Lasso(**lr_best_params)\n",
    "print(f\"線形回帰　採用されたパラメータ：{lr_best_params}\")\n",
    "models['Lasso'] = best_lr\n",
    "print(\"-------------------------------------------\")\n",
    "joblib.dump(lr_best_params, os.path.join(file_path, 'lr_best_params.pkl'))\n",
    "\n",
    "# 勾配ブースティング回帰\n",
    "print(\"---------- 勾配ブースティング回帰 ----------\")\n",
    "gbr_init = optuna.create_study(direction='minimize')\n",
    "gbr_init.optimize(objective_gbr, n_trials=20)\n",
    "gbr_best_params = gbr_init.best_params\n",
    "best_gbr = GradientBoostingRegressor(**gbr_best_params)\n",
    "print(f\"勾配ブースティング回帰　採用されたパラメータ{gbr_best_params}\")\n",
    "models['GBR'] = best_gbr\n",
    "print(\"-----------------------------------------------------------\")\n",
    "joblib.dump(gbr_best_params, os.path.join(file_path, 'gbr_best_params.pkl'))\n",
    "\n",
    "# ランダムフォレスト\n",
    "print(\"---------- ランダムフォレスト(RandomForest) ----------\")\n",
    "rf_init = optuna.create_study(direction='minimize')\n",
    "rf_init.optimize(objective_rf, n_trials=20)\n",
    "rf_best_params = rf_init.best_params\n",
    "best_rf = RandomForestRegressor(**rf_best_params)\n",
    "print(f\"ランダムフォレスト　採用されたパラメータ{rf_best_params}\")\n",
    "models['RF'] = best_rf\n",
    "print(\"------------------------------------------------------------\")\n",
    "joblib.dump(rf_best_params, os.path.join(file_path, 'rf_best_params.pkl'))\n",
    "\n",
    "# XGBoost\n",
    "print(\"---------- XGBoost(eXtreme Gradient Boosting) ----------\")\n",
    "xgb_init = optuna.create_study(direction='minimize')\n",
    "xgb_init.optimize(objective_xgb, n_trials=20)\n",
    "xgb_best_params = xgb_init.best_params\n",
    "best_xgb = xgb.XGBRegressor(**xgb_best_params)\n",
    "print(f\"XGBoost　採用されたパラメータ{xgb_best_params}\")\n",
    "models['XGB'] = best_xgb\n",
    "print(\"--------------------------------------------------------\")\n",
    "joblib.dump(xgb_best_params, os.path.join(file_path, 'xgb_best_params.pkl'))\n",
    "\n",
    "# SVM\n",
    "print(\"---------- SVM(Support Vector Machine) ----------\")\n",
    "svm_init = optuna.create_study(direction='minimize')\n",
    "svm_init.optimize(objective_svm, n_trials=20)\n",
    "svm_best_params = svm_init.best_params\n",
    "best_svm = SVR(**svm_best_params)\n",
    "print(f\"SVM　採用されたパラメータ{svm_best_params}\")\n",
    "models['SVM'] = best_svm\n",
    "print(\"-------------------------------------------------\")\n",
    "joblib.dump(svm_best_params, os.path.join(file_path, 'svm_best_params.pkl'))\n",
    "\n",
    "# LightGBM\n",
    "print(\"---------- LightGBM ----------\")\n",
    "gbm_init = optuna.create_study(direction='minimize')\n",
    "gbm_init.optimize(objective_lgb, n_trials=10)\n",
    "gbm_best_params = gbm_init.best_params\n",
    "best_gbm = lgb.LGBMRegressor(**gbm_best_params)\n",
    "print(f\"LightGBM　採用されたパラメータ{gbm_best_params}\")\n",
    "models['LightGBM'] = best_gbm\n",
    "print(\"-----------------------------\")\n",
    "joblib.dump(gbm_best_params, os.path.join(file_path, 'gbm_best_params.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b10f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適モデルのRMSE\n",
    "print(\"BEST RMSE\")\n",
    "print(f\"線形回帰モデル　{lr_init.best_value}\")\n",
    "print(f\"勾配ブースティング回帰　{gbr_init.best_value}\")\n",
    "print(f\"RandomForest　{rf_init.best_value}\")\n",
    "print(f\"XGBoost　{xgb_init.best_value}\")\n",
    "print(f\"SVM　{svm_init.best_value}\")\n",
    "print(f\"LightGBM　{gbm_init.best_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db793dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_Hat = []\n",
    "y_svm = []\n",
    "y_lr = []\n",
    "\n",
    "end = min(2276, len(df))\n",
    "\n",
    "for i in np.arange(1776, end):\n",
    "    if (i - 1776) % 50 == 0:\n",
    "        print(f\"Processing index: {i} / 2276\")\n",
    "\n",
    "    learn = df[0:i].copy().dropna()\n",
    "    test = df[i:i+1].copy()\n",
    "\n",
    "    learn = learn.reset_index(drop=True)\n",
    "    test = test.reset_index(drop=True)\n",
    "\n",
    "    learn = learn[learn[\"final_mes_time\"] < test['process_end_time'][0]]\n",
    "\n",
    "    X_l = learn.drop(columns=['process_end_time','final_mes_time',target], axis=1)\n",
    "    y_l = learn[target]\n",
    "    X_t = test.drop(columns=['process_end_time','final_mes_time',target], axis=1)\n",
    "\n",
    "    scaler_x = StandardScaler()\n",
    "    X_l_scaled = scaler_x.fit_transform(X_l)\n",
    "    X_t_scaled = scaler_x.transform(X_t)\n",
    "\n",
    "    best_svm.fit(X_l_scaled, y_l)\n",
    "    best_lr.fit(X_l_scaled, y_l)\n",
    "\n",
    "    pred_train_svm = best_svm.predict(X_l_scaled)\n",
    "    pred_train_lr = best_lr.predict(X_l_scaled)\n",
    "    \n",
    "    base_train_pred = pred_train_svm * 0.6 + pred_train_lr * 0.4\n",
    "    residuals = y_l - base_train_pred\n",
    "\n",
    "    best_rf.fit(X_l_scaled, residuals)\n",
    "\n",
    "    pred_svm = best_svm.predict(X_t_scaled)\n",
    "    pred_lr = best_lr.predict(X_t_scaled)\n",
    "    \n",
    "    pred_resid = best_rf.predict(X_t_scaled)\n",
    "\n",
    "    y_Hat.append((pred_svm[0] * 0.6 + pred_lr[0] * 0.4 + pred_resid[0]))\n",
    "    y_svm.append(pred_svm[0])\n",
    "    y_lr.append(pred_lr[0])\n",
    "\n",
    "Y_t = df[\"OV\"][1776:2276].reset_index(drop=True)\n",
    "Y_t = Y_t.reset_index()['OV']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(Y_t, label='Actual OV', color='black', linestyle='--')\n",
    "\n",
    "yh = np.array(y_Hat)\n",
    "rmse = np.sqrt(mean_squared_error(Y_t, yh))\n",
    "plt.plot(yh, label=f'Ensemble+Resid RMSE: {rmse:.2f}', alpha=0.8)\n",
    "print(f\"アンサンブル学習(残差補正あり): {rmse}\")\n",
    "\n",
    "yh_svm = np.array(y_svm)\n",
    "rmse_svm = np.sqrt(mean_squared_error(Y_t, yh_svm))\n",
    "plt.plot(yh_svm, label=f'SVM RMSE: {rmse_svm:.2f}', alpha=0.8)\n",
    "print(f\"SVM: {rmse_svm}\")\n",
    "\n",
    "yh_lr = np.array(y_lr)\n",
    "rmse_lr = np.sqrt(mean_squared_error(Y_t, yh_lr))\n",
    "plt.plot(yh_lr, label=f'Linear Regression RMSE: {rmse_lr:.2f}', alpha=0.8)\n",
    "print(f\"線形回帰: {rmse_lr}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Prediction Comparison with Residual Learning\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
